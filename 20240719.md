# 2024년 7월 19일

### AI 공부
+ **마르코프 의사결정 모델(MDP)**
    + 인공지능이 **학습하고자 하는 방식을 공식화하여 추론하는  모델**
    + **벽돌게임**을 예로 들어 설명하자면
        |MDP|예시|
        |---|---|
        |**Environment(환경)**|벽돌깨기|
        |**State(상태)**|공의 방향,위치,벽돌의 존재유무 등|
        |**Action(행동)**|바를 왼쪽,오른쪽으로 이동시키는 등의 행동|
        |**Reward(보상)**|**Action**의 결과로 나오는 점수||
        |**Policy(정책)**|**Action**이 **Environment**를 변화시키고 **State**값이 변하게 되며 이를 통해 Agent가 다시 **Action**을 선택하는 것|
    + 위 표의 요소들에 따라 MDP의 **Process**가 결정된다
    + 이렇게 결정된 여러 **Process** 중 하나의 **Episode**가 상태,행동 그리고 그로 인한 **보상**이라는 **Sequence**를 형성한다
+ **Discounted Future Reward**
    + 오랫동안 좋은 수행능력을 **유지**하기 위해 당장의 Reward를 포함해 미래에도 좋은 Reward를 받을 수 있도록 해야한다
    + MDP의 Process가 한 번 실행이 되는 것을 보면 하나의 **Episode**의 **Reward**를 예측가능하다
    + 특정 시점에서 얻는 **Reward**양을 다음의 수식으로 계산 가능하다
    \[ R_t = \sum_{t' = t}^{T} r^{t'-t} r_{t'} \]